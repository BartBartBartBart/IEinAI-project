{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0d1181",
   "metadata": {},
   "source": [
    "# Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f22dcc",
   "metadata": {},
   "source": [
    "# AI Feynman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0a7edd",
   "metadata": {},
   "source": [
    "Load imports and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d0cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AI Feynman \n",
    "from datasets import load_dataset\n",
    "import torch \n",
    "import numpy as np\n",
    "import os \n",
    "import sys \n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "ai_feynman_easy = load_dataset(\"yoshitomo-matsubara/srsd-feynman_easy\") # 30 equations\n",
    "ai_feynman_medium = load_dataset(\"yoshitomo-matsubara/srsd-feynman_medium\") # 40 equations\n",
    "ai_feynman_hard = load_dataset(\"yoshitomo-matsubara/srsd-feynman_hard\") # 50 equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b7cf4",
   "metadata": {},
   "source": [
    "Prep the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33380dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_feynman = ai_feynman_hard # change to easy or medium as needed\n",
    "print(ai_feynman)\n",
    "\n",
    "# dict containing the training data for each equation (every 8000 samples for train, 1000 for validation and test)\n",
    "equation_data = {}\n",
    "for i in range(0, len(ai_feynman[\"train\"]) // 8000):\n",
    "    X_train, y_train = [], []\n",
    "    X_val, y_val = [], []\n",
    "    X_test, y_test = [], []\n",
    "\n",
    "    # Process the training, validation, and test data\n",
    "    for train_data in ai_feynman[\"train\"][\"text\"][i * 8000:(i + 1) * 8000]:\n",
    "        train_values = train_data.split(\" \")\n",
    "        X_train.append([float(v) for v in train_values[:-1]])\n",
    "        y_train.append(float(train_values[-1]))\n",
    "\n",
    "    for val_data in ai_feynman[\"validation\"][\"text\"][i * 1000:(i + 1) * 1000]:\n",
    "        val_values = val_data.split(\" \")\n",
    "        X_val.append([float(v) for v in val_values[:-1]])\n",
    "        y_val.append(float(val_values[-1]))\n",
    "\n",
    "    for test_data in ai_feynman[\"test\"][\"text\"][i * 1000:(i + 1) * 1000]:\n",
    "        test_values = test_data.split(\" \")\n",
    "        X_test.append([float(v) for v in test_values[:-1]])\n",
    "        y_test.append(float(test_values[-1]))\n",
    "\n",
    "    # Store the data in the equation_data dictionary\n",
    "    equation_data[i] = {\n",
    "        \"X_train\": torch.Tensor(X_train),\n",
    "        \"y_train\": torch.Tensor(y_train),\n",
    "        \"X_val\": torch.Tensor(X_val),\n",
    "        \"y_val\": torch.Tensor(y_val),\n",
    "        \"X_test\": torch.Tensor(X_test),\n",
    "        \"y_test\": torch.Tensor(y_test)\n",
    "    }\n",
    "\n",
    "print(f\"Number of equations: {len(equation_data)}\")\n",
    "print(f\"Shape of training data for first equation: {equation_data[1]['X_train'].shape}, {equation_data[1]['y_train'].shape}\")\n",
    "print(f\"Shape of validation data for first equation: {equation_data[1]['X_val'].shape}, {equation_data[1]['y_val'].shape}\")\n",
    "print(f\"Shape of test data for first equation: {equation_data[1]['X_test'].shape}, {equation_data[1]['y_test'].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0af385",
   "metadata": {},
   "source": [
    "Some metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01cab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_r2(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    if ss_tot == 0:\n",
    "        ss_tot = 1e-10  # Avoid division by zero\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def adjusted_r2(y_true, y_pred, n, k):\n",
    "    r2 = positive_r2(y_true, y_pred)\n",
    "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - k - 1)\n",
    "    return adj_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f2a78",
   "metadata": {},
   "source": [
    "## GFN-SR\n",
    "\n",
    "To run it with a LSTM RNN forward policy, make sure to set the policy to 'RNN' in the function call. For transformer forward policy use 'TRN'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db8a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(os.getcwd(), 'gfn-sr'))\n",
    "from train import train_gfn_sr_adapted\n",
    "\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "adjusted_r2_scores = []\n",
    "for i in range(0, len(equation_data)): \n",
    "    print(f\"\\nProcessing equation {i}...\")\n",
    "    X_train = equation_data[i][\"X_train\"]\n",
    "    y_train = equation_data[i][\"y_train\"]\n",
    "    X_val = equation_data[i][\"X_val\"]\n",
    "    y_val = equation_data[i][\"y_val\"]\n",
    "\n",
    "    batch_size = 64\n",
    "    num_epochs = 100\n",
    "\n",
    "    try:\n",
    "        gfn_sr, env, errs, avg_mses, top_mses = train_gfn_sr_adapted(X_train, y_train, batch_size, num_epochs, show_plot=False, use_gpu=True, policy=\"RNN\", verbose=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error training GFN-SR for equation {i}: {e}\")\n",
    "        continue\n",
    "    expr_gfnsr_trn = str(env.reward_manager.best_expr)\n",
    "    print(f\"Best expression from GFN-SR: {expr_gfnsr_trn}\")\n",
    "\n",
    "    n_terms = X_val.shape[1]  \n",
    "    eval_dict = {f\"x{j+1}\": X_val[:, j] for j in range(n_terms)}\n",
    "    eval_dict.update({\n",
    "        'cos': torch.cos,\n",
    "        'sin': torch.sin,\n",
    "        'exp': torch.exp,\n",
    "        'sqrt': torch.sqrt,\n",
    "        'log': torch.log,\n",
    "        'inv': lambda x: 1/x,\n",
    "        '0': torch.Tensor([0]),\n",
    "        'square': torch.square,\n",
    "    })\n",
    "    if expr_gfnsr_trn.startswith(\"square(0)\"):\n",
    "        print(f\"GFN-SR output is square(0) for equation {i}. Setting output to zero tensor.\")\n",
    "        y_gfnsr_trn = torch.zeros_like(y_val)\n",
    "    else:\n",
    "        y_gfnsr_trn = eval(expr_gfnsr_trn, eval_dict)\n",
    "    \n",
    "    # if it is a tensor and it contains nan -> 0\n",
    "    if isinstance(y_gfnsr_trn, torch.Tensor) and torch.isnan(y_gfnsr_trn).any():\n",
    "        print(f\"GFN-SR output contains NaN for equation {i}. Setting NaN values to 0.\")\n",
    "        y_gfnsr_trn = torch.nan_to_num(y_gfnsr_trn)\n",
    "    elif not isinstance(y_gfnsr_trn, torch.Tensor) and y_gfnsr_trn == 0:\n",
    "        print(f\"GFN-SR output is 0 for equation {i}. Setting output to zero tensor.\")\n",
    "        y_gfnsr_trn = torch.zeros_like(y_val)\n",
    "\n",
    "    r2_score_gfnsr = positive_r2(np.array(y_val), np.array(y_gfnsr_trn))\n",
    "    mse_score_gfnsr = mse_loss(np.array(y_val), np.array(y_gfnsr_trn))\n",
    "    adj_r2_score_gfnsr = adjusted_r2(np.array(y_val), np.array(y_gfnsr_trn), len(y_val), n_terms)\n",
    "    mse_scores.append(mse_score_gfnsr)\n",
    "    r2_scores.append(r2_score_gfnsr)\n",
    "    adjusted_r2_scores.append(adj_r2_score_gfnsr)\n",
    "    print(f\"GFN-SR R^2 score: {r2_score_gfnsr}\")\n",
    "    print(f\"GFN-SR adjusted R^2 score: {adj_r2_score_gfnsr}\")\n",
    "    print(f\"GFN-SR MSE loss: {mse_score_gfnsr}\")\n",
    "\n",
    "\n",
    "print(f\"Average MSE score across all equations: {np.mean(mse_scores)}\")\n",
    "print(f\"Average R^2 score across all equations: {np.mean(r2_scores)}\")\n",
    "print(f\"Average adjusted R^2 score across all equations: {np.mean(adjusted_r2_scores)}\")\n",
    "print(f\"Standard deviation of MSE scores: {np.std(mse_scores)}\")\n",
    "print(f\"Standard deviation of R^2 scores: {np.std(r2_scores)}\")\n",
    "print(f\"Standard deviation of adjusted R^2 scores: {np.std(adjusted_r2_scores)}\")\n",
    "\n",
    "# Post-processing\n",
    "r2_gp_finite = [r2 for r2 in r2_scores if not (np.isinf(r2) or np.isnan(r2))]\n",
    "r2_gp_capped = [max(0, r2) for r2 in r2_gp_finite]\n",
    "print(f\"R^2 scores for GPLearn (capped): {r2_gp_capped}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e41ce0f",
   "metadata": {},
   "source": [
    "## GPLearn\n",
    "Has no GPU optimization so very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e453e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gplearn.genetic import SymbolicRegressor\n",
    "\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "adjusted_r2_scores = []\n",
    "for i in range(0, len(equation_data)): \n",
    "    print(f\"\\nProcessing equation {i}...\")\n",
    "    X_train = equation_data[i][\"X_train\"]\n",
    "    y_train = equation_data[i][\"y_train\"]\n",
    "    X_val = equation_data[i][\"X_val\"]\n",
    "    y_val = equation_data[i][\"y_val\"]\n",
    "\n",
    "    est_gp = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, stopping_criteria=0.01,\n",
    "                        p_crossover=0.7, p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, p_point_mutation=0.1,\n",
    "                        max_samples=0.9, verbose=0,\n",
    "                        parsimony_coefficient=0.01, random_state=0)\n",
    "    est_gp.fit(X_train, y_train)\n",
    "    y_gp = est_gp.predict(X_val)\n",
    "\n",
    "    r2_gp = positive_r2(np.array(y_val), np.array(y_gp))\n",
    "    mse_gp = mse_loss(np.array(y_val), np.array(y_gp))\n",
    "    mse_scores.append(mse_gp)\n",
    "    r2_scores.append(r2_gp)\n",
    "    expr_gp = est_gp._program\n",
    "    \n",
    "    print(f\"Best expression from GPLearn: {expr_gp}\")\n",
    "    print(f\"GPLearn R^2 score: {r2_gp}\")\n",
    "    print(f\"GPLearn MSE loss: {mse_gp}\")\n",
    "\n",
    "print(f\"Average MSE score across all equations: {np.mean(mse_scores)}\")\n",
    "print(f\"Average R^2 score across all equations: {np.mean(r2_scores)}\")\n",
    "print(f\"Standard deviation of MSE scores: {np.std(mse_scores)}\")\n",
    "print(f\"Standard deviation of R^2 scores: {np.std(r2_scores)}\")\n",
    "\n",
    "# Post-processing\n",
    "r2_gp_finite = [r2 for r2 in r2_scores if not (np.isinf(r2) or np.isnan(r2))]\n",
    "r2_gp_capped = [max(0, r2) for r2 in r2_gp_finite]\n",
    "print(f\"R^2 scores for GPLearn (capped): {r2_gp_capped}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d2027",
   "metadata": {},
   "source": [
    "## PySR\n",
    "Ran with niterations = 10 for easy, 3 for medium and hard to save compute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88fa3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysr import PySRRegressor\n",
    "\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "adjusted_r2_scores = []\n",
    "for i in range(0, len(equation_data)): \n",
    "    print(f\"\\nProcessing equation {i}...\")\n",
    "    X_train = equation_data[i][\"X_train\"]\n",
    "    y_train = equation_data[i][\"y_train\"]\n",
    "    X_val = equation_data[i][\"X_val\"]\n",
    "    y_val = equation_data[i][\"y_val\"]\n",
    "\n",
    "    pysr = PySRRegressor(\n",
    "        niterations=3,  # < Increase me for better results\n",
    "        binary_operators=[\"+\", \"*\"],\n",
    "        unary_operators=[\n",
    "            \"cos\",\n",
    "            \"exp\",\n",
    "            \"sin\",\n",
    "            \"inv(x) = 1/x\",\n",
    "            # ^ Custom operator (julia syntax)\n",
    "        ],\n",
    "        extra_sympy_mappings={\"inv\": lambda x: 1 / x},\n",
    "        # ^ Define operator for SymPy as well\n",
    "        elementwise_loss=\"loss(prediction, target) = (prediction - target)^2\",\n",
    "        # ^ Custom loss function (julia syntax)\n",
    "        verbosity=0\n",
    "    )\n",
    "    pysr.fit(X_train, y_train)\n",
    "    y_pysr = pysr.predict(X_val)\n",
    "    expr_pysr = pysr.get_best().equation\n",
    "    \n",
    "    r2_pysr = positive_r2(np.array(y_val), np.array(y_pysr))\n",
    "    mse_pysr = mse_loss(np.array(y_val), np.array(y_pysr))\n",
    "    mse_scores.append(mse_pysr)\n",
    "    r2_scores.append(r2_pysr)\n",
    "\n",
    "\n",
    "    print(f\"Best expression from PySR: {expr_pysr}\")\n",
    "    print(f\"PySR R^2 score: {r2_pysr}\")\n",
    "    print(f\"PySR MSE loss: {mse_pysr}\")\n",
    "\n",
    "\n",
    "print(f\"Average MSE score across all equations: {np.mean(mse_scores)}\")\n",
    "print(f\"Average R^2 score across all equations: {np.mean(r2_scores)}\")\n",
    "print(f\"Standard deviation of MSE scores: {np.std(mse_scores)}\")\n",
    "print(f\"Standard deviation of R^2 scores: {np.std(r2_scores)}\")\n",
    "\n",
    "r2_pysr_capped = [max(0, r2) for r2 in r2_scores]\n",
    "print(f\"R^2 scores for PySR (capped): {r2_pysr_capped}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716f8c4",
   "metadata": {},
   "source": [
    "## RandomForest + DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e1d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "r2_scores_rf = []\n",
    "r2_scores_dt = []\n",
    "for i in range(0, len(equation_data)): \n",
    "    print(f\"\\nProcessing equation {i}...\")\n",
    "    X_train = equation_data[i][\"X_train\"]\n",
    "    y_train = equation_data[i][\"y_train\"]\n",
    "    X_val = equation_data[i][\"X_val\"]\n",
    "    y_val = equation_data[i][\"y_val\"]\n",
    "\n",
    "    est_tree = DecisionTreeRegressor()\n",
    "    est_tree.fit(X_train, y_train) \n",
    "    score_tree = est_tree.score(X_val, y_val)\n",
    "    r2_scores_dt.append(score_tree)\n",
    "\n",
    "    est_rf = RandomForestRegressor()\n",
    "    est_rf.fit(X_train, y_train)\n",
    "    score_rf = est_rf.score(X_val, y_val)\n",
    "    r2_scores_rf.append(score_rf)\n",
    "\n",
    "    print(f\"Decision Tree R^2 score: {score_tree}\")    \n",
    "    print(f\"RF R^2 score: {score_rf}\")\n",
    "\n",
    "\n",
    "print(f\"Average R^2 score across all equations for RF: {np.mean(r2_scores_rf)}\")\n",
    "print(f\"Average R^2 score across all equations for DT: {np.mean(r2_scores_dt)}\")\n",
    "print(f\"Standard deviation of R^2 scores for RF: {np.std(r2_scores_rf)}\")\n",
    "print(f\"Standard deviation of R^2 scores for DT: {np.std(r2_scores_dt)}\")\n",
    "\n",
    "r2_rf_capped = [max(0, r2) for r2 in r2_scores_rf]\n",
    "r2_dt_capped = [max(0, r2) for r2 in r2_scores_dt]\n",
    "print(f\"R^2 scores for RF (capped): {r2_rf_capped}\")\n",
    "print(f\"R^2 scores for DT (capped): {r2_dt_capped}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
